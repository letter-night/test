# @package _global_
model:
  name: DynamicCausalPFN
  dynamic_causal_pfn:
    _target_: src.models.dynamic_causal_pfn.DynamicCausalPFN

    # Keep the same convention as GT: model sees padded history + (optional) projection horizon
    # If your PFN uses only history length, you can set this to ${dataset.max_seq_length} instead.
    max_seq_length: ${dataset.max_seq_length}

    # PFN backbone hyperparams
    seq_hidden_units:                    # embedding dim (embed_dim)
    hr_size:                             # per-time hidden representation size
    fc_hidden_units:
    dropout_rate:
    patch_size:                          # feature patch size (must be even if you use patch_size//2)
    n_heads:
    d_ff:
    e_layers:
    activation: gelu

    # G-computation / training
    projection_horizon: 0                # overwritten by training script loop
    max_grad_norm: 0.0
    batch_size:

    optimizer:
      optimizer_cls: adam
      learning_rate:
      weight_decay: 0.0
      lr_scheduler: False

    tune_hparams: False
    tune_range: 50
    hparams_grid:
    resources_per_trial:

exp:
  update_alpha: False
